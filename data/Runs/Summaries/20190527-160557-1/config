process_index>> 1
batch_size>> 64
observation_type>> vector
exploration>> False
threshold_ask>> 10.0
summary_update_period>> 100
huber_loss_delta>> 1.0
advice_asking_mode>> 3
use_teaching>> False
gamma>> 0.99
max_episodes>> 20000.0
target_update_period>> 10000.0
hidden_layer_size>> 256
n_agents>> 3
budget_ask>> 5000
n_actions>> 5
agents_knowledge_state>> 0
evaluation_period>> 100
adam_epsilon>> 0.00015
game_width>> 10
frame_stack_size>> 1
train_period>> 2
model_save_period>> 10000.0
advice_giving_mode>> 1
n_landmarks>> 3
machine_name>> LAB-1
replay_memory_init_size>> 10000.0
importance_threshold_give>> 1.0
t_max>> 25
learning_rate>> 0.001
run_id>> None
seed>> 303
game_height>> 10
evaluation_seed>> 200
reuse_action>> False
hysteretic_multiplier>> 1.0
n_optimizer_steps>> 245000
replay_memory_capacity>> 25000.0
threshold_give>> 3.0
budget_give>> 5000
n_evaluation_levels>> 50
